{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "***\n",
    "\n",
    "Logistic regression is used for answerering yes and no questions or questions involving the odds of something happening. To do this, it uses the \"logistic\" function.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/2000px-Logistic-curve.svg.png\" width=30%, height=30% />\n",
    "\n",
    "This function is derived from the following:\n",
    "\n",
    "### Odds Ratio\n",
    "We want to know the odds of something happening. This can be exressed as an odds ratio\n",
    "$$Odds Ratio (OR) = \\frac{p}{1 - p}$$\n",
    "where $p$ is the probability of the event.\n",
    "\n",
    "If that ratio is, let's say, > 0.75, then we're pretty confident about the event being very likely. If that ratio is, say, < 0.25, then we might say that event is very unlikely.\n",
    "\n",
    "### Logit Function\n",
    "We can use a derivation of this function called the \"Logit Function\" which is just a Log of the odds ratio above.\n",
    "$$logit(p) = \\log(\\frac{p}{1 - p})$$\n",
    "\n",
    "We want this logit function to be on the y axis and $\\theta_0 x_0 + \\theta_1X$ (i.e. our linear equation) to be on the x axis. Thus, we can say:\n",
    "\n",
    "$$logit(p) = \\log(\\frac{p}{1 - p}) = \\theta_0 x_0 + \\theta_1X$$\n",
    "\n",
    "### Logistic Function\n",
    "\n",
    "One more step! We just need to solve for $p(X)$ which gives us:\n",
    "\n",
    "$$p(X) = \\frac{1}{1 + e^{\\theta_0 x_0 + \\theta_1X}}$$\n",
    "\n",
    "### Kaggle Competition Titanic Dataset\n",
    "\n",
    "We'll be using the dataset that is provided by the Titanic competition hosted at Kaggle.\n",
    "The goal of this competition is to use the dataset to build a model that predicts who survived and who didn't.\n",
    "\n",
    "Let's take a look at the dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be skipping any kind of preprocessing or feature engineering as this document is meant to just focus on logistic regression.\n",
    "\n",
    "Since we're wanting to predict the Survived column, we need to choose a couple predictors; let's use Pclass and Sex. We can start with the model:\n",
    "$$Survived = \\theta_0 * x_0 + \\theta_1 * Pclass + \\theta_2 * Sex$$\n",
    "\n",
    "And since we're calculating the probability that someone survived, the second equation would just be:\n",
    "$$z = Prob(Survived)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.464195\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# add a column of 0s for the intercept\n",
    "train['intercept'] = 1.0\n",
    "\n",
    "# make the Sex column a category type\n",
    "from sklearn import preprocessing\n",
    "le_sex = preprocessing.LabelEncoder()\n",
    "train['Sex'] = le_sex.fit_transform(train['Sex'])\n",
    "\n",
    "# identify the independent variables\n",
    "columns = ['intercept', 'Pclass', 'Sex']\n",
    "logistic_function = sm.Logit(train['Survived'], train[columns])\n",
    "model_parameters = logistic_function.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out how our model adjusted the parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept    3.294642\n",
       "Pclass      -0.960553\n",
       "Sex         -2.643398\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = model_parameters.params\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can update our model now to show:\n",
    "$$Survived = 3.294642 * x_0 + -0.960553 * Pclass + -2.643398 * Sex$$\n",
    "\n",
    "Given the above, we can say the probability of someone surviving is:\n",
    "$$p(z) = \\frac{1}{1 + e^{\\theta_0 * x_0 + \\theta_1 * Pclass + \\theta_2 * Sex}}$$\n",
    "\n",
    "Let's write that in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def probability_of_z(pclass, sex, theta):\n",
    "    z = theta[0] + pclass * theta[1] + sex * theta[2]\n",
    "    return 1 / (1 + exp(-1*z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got everything set up, let's make a prediction. First we need to see how scikit-learn encoded our categorical variable Sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female' 'male']\n"
     ]
    }
   ],
   "source": [
    "print le_sex.inverse_transform([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, so if we wanted to see how a woman in first class faired, we could make a prediction like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91166115474379972"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_of_z(1, 0, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like she would have faired pretty well. What about a guy in third class..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.097052204431359895"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_of_z(3, 1, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's abysmal. But it makes sense, the people in the lower parts of the ship probably didn't have a very good chance of escaping when the iceberg hit and the Titanic is known for saving women and children first. Unfortunately, it looks like if you were a poor male on the Titanic, you almost certainly didn't survive - at least according to our logistic regression model :).\n",
    "\n",
    "Now there are other things we could have done like more pre-processing of the data such as engineering new features. We could have also used other variables in our logistic regression function that would have helped our model be more accurate. But now we know the basics of logistic regression!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
